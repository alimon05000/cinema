<!doctype html>
<html lang="ru">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover" />
<title>ClipSuggest — демо</title>
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="theme-color" content="#071024">
<style>
  :root{
    --bg:#071024; --panel:#0f172a; --accent:#7c3aed; --muted:rgba(255,255,255,0.6);
  }
  *{box-sizing:border-box}
  html,body{height:100%;margin:0;font-family:Inter,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;color:#eef2ff;background:linear-gradient(180deg,#071024,#071d33)}
  header{height:64px;display:flex;align-items:center;justify-content:space-between;padding:12px 18px}
  .logo{font-weight:700;font-size:20px}
  .logo .dot{color:var(--accent)}
  main{display:flex;gap:18px;padding:18px;height:calc(100% - 64px)}
  .left{width:360px;background:linear-gradient(180deg, rgba(255,255,255,0.02), transparent);border-radius:12px;padding:14px;overflow:auto}
  .right{flex:1;display:flex;flex-direction:column;gap:12px}
  .uploader{border:2px dashed rgba(255,255,255,0.04);border-radius:10px;padding:14px;text-align:center;cursor:pointer}
  .uploader input{display:none}
  video{max-width:100%;border-radius:8px;background:#000}
  .stage{flex:1;background:linear-gradient(180deg, rgba(255,255,255,0.01), rgba(255,255,255,0.02));border-radius:12px;padding:12px;display:flex;flex-direction:column}
  .clips{display:flex;flex-direction:column;gap:8px;margin-top:12px}
  .clip{display:flex;gap:10px;align-items:center;background:linear-gradient(180deg, rgba(255,255,255,0.01), transparent);padding:8px;border-radius:8px}
  .thumb{width:140px;height:78px;background:#000;border-radius:6px;display:flex;align-items:center;justify-content:center;overflow:hidden}
  .thumb canvas, .thumb img{width:140px;height:78px;object-fit:cover}
  .meta{flex:1}
  .btn{padding:6px 10px;border-radius:8px;background:transparent;border:1px solid rgba(255,255,255,0.06);color:inherit;cursor:pointer;margin-left:6px}
  .btn.primary{background:linear-gradient(90deg,var(--accent),#4f46e5);border:0}
  footer{height:48px;display:flex;align-items:center;justify-content:center;color:var(--muted)}
  .sidebar-item{margin-bottom:12px}
  label.small{display:block;font-size:12px;color:var(--muted);margin-bottom:6px}
  .editor-modal{position:fixed;inset:0;background:rgba(0,0,0,0.6);display:none;align-items:center;justify-content:center;padding:20px}
  .editor-panel{width:820px;max-width:100%;background:var(--panel);border-radius:12px;padding:14px;box-shadow:0 6px 30px rgba(0,0,0,0.6)}
  .srt-list{max-height:240px;overflow:auto;margin-top:8px}
  .srt-row{display:flex;gap:8px;align-items:center;margin-bottom:8px}
  input[type="time"], input[type="text"], textarea{width:100%;padding:6px;border-radius:6px;border:1px solid rgba(255,255,255,0.06);background:transparent;color:inherit}
  .muted{color:var(--muted);font-size:13px}
  .small{font-size:13px}
  .notice{background:rgba(124,58,237,0.08);padding:8px;border-radius:8px;color:#dfe6ff;margin-bottom:8px}
  .progress{height:8px;background:#0b1220;border-radius:999px;overflow:hidden}
  .progress > i{display:block;height:100%;background:linear-gradient(90deg,var(--accent),#4f46e5);width:0%}
  .flex{display:flex;align-items:center}
</style>
</head>
<body>
<header>
  <div class="logo">ClipSuggest<span class="dot">.</span></div>
  <div style="display:flex;gap:8px;align-items:center">
    <button id="btnReset" class="btn">Сброс</button>
    <a id="hintIntegrate" class="btn" href="#" title="Как подключить автосубтитры">Автосубтитры (интегр.)</a>
  </div>
</header>

<main>
  <aside class="left">
    <div class="sidebar-item">
      <label class="small">Загрузить видео</label>
      <div class="uploader" id="uploader">
        <div id="uploader-text">Перетащи видео сюда или нажми чтобы выбрать</div>
        <input id="file" type="file" accept="video/*">
      </div>
      <div class="muted" style="margin-top:8px">Поддерживаемые форматы: mp4, webm, mov (зависит от браузера).</div>
    </div>

    <div class="sidebar-item">
      <label class="small">Настройки генерации</label>
      <div style="display:flex;gap:8px;margin-bottom:8px">
        <input id="count" type="number" min="1" max="12" value="6" style="width:100%;padding:6px;border-radius:6px;background:transparent;border:1px solid rgba(255,255,255,0.06)">
        <select id="preset" style="width:100px;padding:6px;border-radius:6px;background:transparent;border:1px solid rgba(255,255,255,0.06)">
          <option value="mixed">mix</option>
          <option value="short">короткие</option>
          <option value="long">длинные</option>
        </select>
      </div>
      <button id="btnGenerate" class="btn primary" style="width:100%">Сгенерировать отрывки</button>
    </div>

    <div class="sidebar-item">
      <label class="small">Инструкция по автосубтитрам</label>
      <div class="notice small">
        Браузер не предоставляет надёжный API для распознавания локального аудио. Чтобы добавить авто-субтитры автоматически, нужно отправить сегменты на сервер с моделью (Whisper/Cloud STT). Если нужно — могу подготовить backend-пример.
      </div>
    </div>

    <div class="sidebar-item">
      <label class="small">Прогресс</label>
      <div class="progress" id="progressWrap" style="display:none"><i id="progressBar"></i></div>
      <div id="progressText" class="muted" style="margin-top:6px"></div>
    </div>
  </aside>

  <section class="right">
    <div class="stage">
      <div style="display:flex;gap:12px;align-items:flex-start">
        <div style="flex:1">
          <video id="mainVideo" controls playsinline></video>
        </div>
        <div style="width:220px">
          <div class="muted">Информация</div>
          <div id="videoInfo" class="small muted" style="margin-top:8px">Нет видео</div>
          <div style="margin-top:10px">
            <button id="btnPlayRange" class="btn">▶ Воспроизвести текущий</button>
            <button id="btnExportAll" class="btn">Экспортировать клипы</button>
          </div>
        </div>
      </div>

      <div style="margin-top:12px">
        <div class="muted">Предложенные отрывки</div>
        <div id="clips" class="clips"></div>
      </div>
    </div>
  </section>
</main>

<footer>
  <div class="muted">Демо — отрывки + редактор субтитров • Экспорт клипов с вшитыми субтитрами</div>
</footer>

<!-- Modal: subtitle editor -->
<div id="modal" class="editor-modal" aria-hidden="true">
  <div class="editor-panel">
    <div style="display:flex;justify-content:space-between;align-items:center">
      <div><strong id="modalTitle">Редактирование субтитров</strong><div id="modalRange" class="muted small"></div></div>
      <div style="display:flex;gap:8px">
        <button id="btnAutoSub" class="btn">Автосубтитры (интегр.)</button>
        <button id="btnClose" class="btn">Закрыть</button>
      </div>
    </div>

    <div style="margin-top:10px">
      <label class="small">Список субтитров (SRT)</label>
      <div class="srt-list" id="srtList"></div>
      <div style="display:flex;gap:8px;margin-top:8px">
        <button id="btnAddRow" class="btn">Добавить</button>
        <button id="btnSaveSrt" class="btn primary">Сохранить</button>
        <button id="btnDownloadSrt" class="btn">Скачать SRT</button>
      </div>
    </div>
  </div>
</div>

<script>
/*
 Single-file ClipSuggest
 - Load video
 - Generate N snippets (start,end)
 - For each snippet: preview (capture frame), play, edit subtitles (manual), download SRT, export burned-in clip (canvas recording)
*/

const fileInput = document.getElementById('file');
const uploader = document.getElementById('uploader');
const uploaderText = document.getElementById('uploader-text');
const mainVideo = document.getElementById('mainVideo');
const clipsWrap = document.getElementById('clips');
const btnGenerate = document.getElementById('btnGenerate');
const countInput = document.getElementById('count');
const presetSel = document.getElementById('preset');
const videoInfo = document.getElementById('videoInfo');
const modal = document.getElementById('modal');
const srtList = document.getElementById('srtList');
const modalTitle = document.getElementById('modalTitle');
const modalRange = document.getElementById('modalRange');
const btnClose = document.getElementById('btnClose');
const btnAddRow = document.getElementById('btnAddRow');
const btnSaveSrt = document.getElementById('btnSaveSrt');
const btnDownloadSrt = document.getElementById('btnDownloadSrt');
const btnAutoSub = document.getElementById('btnAutoSub');
const hintIntegrate = document.getElementById('hintIntegrate');
const progressWrap = document.getElementById('progressWrap');
const progressBar = document.getElementById('progressBar');
const progressText = document.getElementById('progressText');
const btnReset = document.getElementById('btnReset');
const btnExportAll = document.getElementById('btnExportAll');

let currentFile = null;
let suggested = []; // {id, start, end, thumbnailBlob, srt: [{start,end,text}], exporting:false}
let editingClipId = null;

uploader.addEventListener('click', ()=> fileInput.click());
uploader.addEventListener('dragover', e=>{ e.preventDefault(); uploader.style.borderColor='rgba(124,58,237,0.6)'; });
uploader.addEventListener('dragleave', ()=> { uploader.style.borderColor=''; });
uploader.addEventListener('drop', e=>{ e.preventDefault(); uploader.style.borderColor=''; const f = e.dataTransfer.files && e.dataTransfer.files[0]; if (f) handleFile(f); });

fileInput.addEventListener('change', e=> { if (e.target.files && e.target.files[0]) handleFile(e.target.files[0]); });

btnGenerate.addEventListener('click', () => {
  if (!currentFile) return alert('Загрузите видео сначала');
  generateSuggested();
});
btnClose.addEventListener('click', closeModal);
btnAddRow.addEventListener('click', addSrtRow);
btnSaveSrt.addEventListener('click', saveSrtFromEditor);
btnDownloadSrt.addEventListener('click', downloadSrtFromEditor);
btnAutoSub.addEventListener('click', ()=> alert('Автосубтитры: требуется интеграция с сервером или wasm-решением. Могу подготовить пример.'));
hintIntegrate.addEventListener('click', (e)=> { e.preventDefault(); alert('Чтобы автоматически генерировать субтитры — нужен backend (Whisper / Cloud STT). Могу сделать пример API и скрипт.'); });

btnReset.addEventListener('click', ()=>{
  if (!confirm('Сбросить всё?')) return;
  currentFile = null;
  mainVideo.src = '';
  suggested = [];
  clipsWrap.innerHTML = '';
  videoInfo.textContent = 'Нет видео';
  uploaderText.textContent = 'Перетащи видео сюда или нажми чтобы выбрать';
});

btnExportAll.addEventListener('click', async ()=>{
  if (suggested.length === 0) return alert('Нет отрывков для экспорта');
  if (!confirm('Экспортировать все отрывки по очереди? Это займет время.')) return;
  for (let it of suggested) {
    await exportClipWithSubtitles(it.id);
  }
  alert('Экспорт завершён');
});

// handle file
function handleFile(file){
  currentFile = file;
  uploaderText.textContent = file.name + ' (' + Math.round(file.size/1024/1024) + ' MB)';
  const url = URL.createObjectURL(file);
  mainVideo.src = url;
  mainVideo.load();
  mainVideo.onloadedmetadata = () => {
    videoInfo.innerHTML = `Длительность: ${formatTime(mainVideo.duration)} · ${Math.round(file.size/1024/1024)} MB`;
    // auto-generate once loaded
    generateSuggested();
  };
}

// generate suggestions
function generateSuggested(){
  const n = Math.max(1, Math.min(12, parseInt(countInput.value)||6));
  const dur = mainVideo.duration || 0;
  suggested = [];
  if (!dur) return alert('Видео ещё не готово. Подождите загрузки метаданных.');
  // presets: mixed/short/long
  let baseDur;
  const preset = presetSel.value;
  if (preset === 'short') baseDur = 4;
  else if (preset === 'long') baseDur = 15;
  else baseDur = 7;

  // create n suggestions evenly across timeline, with varying lengths around baseDur
  for (let i=0;i<n;i++){
    const tCenter = (i+1) * (dur/(n+1));
    // vary duration
    const v = 1 + ( (i - (n-1)/2) / (n) ); // -..+..
    let length = Math.max(2, Math.round(baseDur * (1 + 0.6 * v)));
    if (length > dur) length = Math.round(Math.max(2, dur/2));
    let start = Math.max(0, tCenter - length/2);
    if (start + length > dur) start = Math.max(0, dur - length);
    suggested.push({
      id: 'clip_'+i+'_'+Date.now(),
      start: start,
      end: start + length,
      srt: [{start:0, end:length, text:''}], // initial empty
      thumbnail: null,
      exporting:false
    });
  }
  renderClips();
  // generate thumbnails asynchronously
  generateThumbnails();
}

// render UI list
function renderClips(){
  clipsWrap.innerHTML = '';
  suggested.forEach(item=>{
    const el = document.createElement('div');
    el.className = 'clip';
    el.id = item.id;
    const thumb = document.createElement('div');
    thumb.className = 'thumb';
    thumb.innerHTML = '<span class="muted small">Превью...</span>';
    if (item.thumbnail){
      const img = document.createElement('img');
      img.src = item.thumbnail;
      thumb.innerHTML = '';
      thumb.appendChild(img);
    }

    const meta = document.createElement('div');
    meta.className = 'meta';
    meta.innerHTML = `<div><strong>${formatTime(item.start)} — ${formatTime(item.end)}</strong> <span class="muted small">(${Math.round(item.end - item.start)} с)</span></div>
      <div class="muted small" id="${item.id}_srtinfo">${item.srt && item.srt.length? (item.srt.length+' субт.)':'Нет субтитров'}</div>`;

    const actions = document.createElement('div');
    actions.style.display='flex';
    actions.style.flexDirection='column';
    actions.style.alignItems='flex-end';
    const playBtn = document.createElement('button'); playBtn.className='btn'; playBtn.textContent='▶ Play'; playBtn.onclick = ()=> playRange(item.start, item.end);
    const editBtn = document.createElement('button'); editBtn.className='btn'; editBtn.textContent='✎ Sub'; editBtn.onclick = ()=> openEditor(item.id);
    const dlSrtBtn = document.createElement('button'); dlSrtBtn.className='btn'; dlSrtBtn.textContent='↓ SRT'; dlSrtBtn.onclick = ()=> downloadSrt(item.id);
    const expBtn = document.createElement('button'); expBtn.className='btn primary'; expBtn.textContent='Export'; expBtn.onclick = ()=> exportClipWithSubtitles(item.id);
    actions.appendChild(playBtn); actions.appendChild(editBtn); actions.appendChild(dlSrtBtn); actions.appendChild(expBtn);

    el.appendChild(thumb);
    el.appendChild(meta);
    el.appendChild(actions);
    clipsWrap.appendChild(el);
  });
}

// generate thumbnail for each suggestion by seeking video
async function generateThumbnails(){
  for (let item of suggested){
    try {
      const dataUrl = await captureFrameAt(item.start + Math.min(0.5, (item.end-item.start)/2));
      item.thumbnail = dataUrl;
      const thumbDiv = document.querySelector('#'+item.id+' .thumb');
      if (thumbDiv){
        thumbDiv.innerHTML = '';
        const img = document.createElement('img'); img.src = dataUrl;
        thumbDiv.appendChild(img);
      }
    } catch(e){
      console.warn('thumb err', e);
    }
  }
}

// capture frame utility: draw video frame to canvas at time t
function captureFrameAt(time){
  return new Promise((resolve, reject)=>{
    const v = mainVideo;
    const prevTime = v.currentTime;
    const prevPaused = v.paused;
    // create offscreen video clone to avoid interrupting mainVideo playback
    const clone = document.createElement('video');
    clone.muted = true;
    clone.playsInline = true;
    clone.src = v.src;
    clone.currentTime = time;
    clone.onloadeddata = () => {
      try {
        const c = document.createElement('canvas');
        c.width = clone.videoWidth || 320;
        c.height = clone.videoHeight || 180;
        const ctx = c.getContext('2d');
        clone.currentTime = time;
        clone.addEventListener('seeked', function onseek(){
          try {
            ctx.drawImage(clone, 0, 0, c.width, c.height);
            const data = c.toDataURL('image/jpeg', 0.7);
            clone.removeEventListener('seeked', onseek);
            resolve(data);
          } catch(err){
            reject(err);
          }
        });
      } catch(err){ reject(err); }
    };
    clone.onerror = (e) => reject(e);
  });
}

// play a small range in main video
let rangeTimeout = null;
function playRange(start, end){
  if (!mainVideo.src) return;
  mainVideo.currentTime = start;
  mainVideo.play().catch(()=>{});
  if (rangeTimeout) clearTimeout(rangeTimeout);
  rangeTimeout = setTimeout(()=> {
    mainVideo.pause();
  }, (end - start) * 1000 + 200);
}

// open subtitle editor modal
function openEditor(clipId){
  const clip = suggested.find(c=>c.id===clipId);
  if (!clip) return;
  editingClipId = clipId;
  modal.style.display = 'flex';
  modal.setAttribute('aria-hidden','false');
  modalTitle.textContent = 'Редактирование субтитров';
  modalRange.textContent = `${formatTime(clip.start)} — ${formatTime(clip.end)} (${Math.round(clip.end-clip.start)} с)`;
  renderSrtList(clip.srt);
}

// close
function closeModal(){ modal.style.display='none'; modal.setAttribute('aria-hidden','true'); editingClipId = null; }

// render srt rows
function renderSrtList(srt){
  srtList.innerHTML = '';
  if (!srt || srt.length===0) srt = [{start:0,end:Math.max(1,(suggested.find(s=>s.id===editingClipId)?.end - suggested.find(s=>s.id===editingClipId)?.start) || 5), text:''}];
  srt.forEach((row, idx)=>{
    const r = document.createElement('div'); r.className='srt-row';
    r.innerHTML = `
      <input class="timeFrom" type="text" value="${toSrtTime(row.start)}" style="width:120px">
      <input class="timeTo" type="text" value="${toSrtTime(row.end)}" style="width:120px">
      <input class="textVal" type="text" value="${row.text}" placeholder="Текст субтитра...">
      <button class="btn smallBtn" data-idx="${idx}" style="width:70px">Удалить</button>
    `;
    srtList.appendChild(r);
    r.querySelector('.smallBtn').onclick = (e)=> { srt.splice(idx,1); renderSrtList(srt); };
  });
}

// add new srt row
function addSrtRow(){
  const clip = suggested.find(c=>c.id===editingClipId);
  if (!clip) return;
  clip.srt = clip.srt || [];
  const len = (clip.end - clip.start) || 5;
  clip.srt.push({start: clip.srt.length? (clip.srt[clip.srt.length-1].end+0.1):0, end: Math.min(len, (clip.srt.length? (clip.srt[clip.srt.length-1].end+2):2)), text: ''});
  renderSrtList(clip.srt);
}

// save srt from editor (reads inputs)
function saveSrtFromEditor(){
  const clip = suggested.find(c=>c.id===editingClipId);
  if (!clip) return;
  const rows = Array.from(srtList.querySelectorAll('.srt-row'));
  const newSrt = rows.map(r=>{
    const from = r.querySelector('.timeFrom').value.trim();
    const to = r.querySelector('.timeTo').value.trim();
    const txt = r.querySelector('.textVal').value;
    return {start: from? fromSrtTime(from):0, end: to? fromSrtTime(to): (clip.end-clip.start), text: txt};
  });
  clip.srt = newSrt;
  document.getElementById(clip.id + '_srtinfo').textContent = (clip.srt.length? (clip.srt.length+' субт.)') : 'Нет субтитров';
  closeModal();
}

// download srt for a clip
function downloadSrt(clipId){
  const clip = suggested.find(c=>c.id===clipId);
  if (!clip) return;
  const srtText = srtToText(clip.srt, clip.start);
  const blob = new Blob([srtText], {type:'text/plain'});
  const a = document.createElement('a');
  a.href = URL.createObjectURL(blob); a.download = 'clip_'+Math.round(clip.start)+'_'+Math.round(clip.end)+'.srt'; a.click();
}

// srt generation (adds clip.start offset)
function srtToText(srt, clipStart){
  if (!srt || srt.length===0) return '';
  let out = '';
  for (let i=0;i<srt.length;i++){
    const row = srt[i];
    const a = secondsToSrtTime( (clipStart || 0) + (row.start || 0) );
    const b = secondsToSrtTime( (clipStart || 0) + (row.end || 0) );
    out += (i+1) + '\n' + a + ' --> ' + b + '\n' + (row.text || '') + '\n\n';
  }
  return out;
}

// export clip with subtitles burned-in
async function exportClipWithSubtitles(clipId){
  const clip = suggested.find(c=>c.id===clipId);
  if (!clip) return alert('Клип не найден');
  if (clip.exporting) return alert('Уже экспортируется');
  clip.exporting = true;
  setProgress(0,'Подготовка...');
  try {
    // create offscreen video element (same src)
    const v = document.createElement('video');
    v.src = mainVideo.src;
    v.muted = false; // keep original audio
    await v.play().catch(()=>{}); // some browsers need user gesture; we'll control playback via currentTime
    v.pause();

    // prepare canvas
    const w = v.videoWidth || 640;
    const h = v.videoHeight || 360;
    const canvas = document.createElement('canvas');
    canvas.width = w; canvas.height = h;
    const ctx = canvas.getContext('2d');

    // playback and record canvas stream
    const stream = canvas.captureStream(30); // 30fps
    const audioStream = await extractAudioStreamFromFile(currentFile);
    if (audioStream){
      // combine audio and canvas stream into one MediaStream
      const mixed = new MediaStream();
      stream.getVideoTracks().forEach(t=> mixed.addTrack(t));
      audioStream.getAudioTracks().forEach(t=> mixed.addTrack(t));
      // record mixed
      const recorder = new MediaRecorder(mixed, {mimeType: 'video/webm;codecs=vp8,opus'});
      const chunks = [];
      recorder.ondataavailable = e=> { if (e.data && e.data.size) chunks.push(e.data); };
      recorder.start(250);
      // play video from clip.start to clip.end, draw frames to canvas and overlay subtitles
      v.currentTime = clip.start;
      const endAt = clip.end;
      await new Promise((resolve, reject) => {
        let rafId;
        const draw = async () => {
          try {
            ctx.fillStyle = '#000'; ctx.fillRect(0,0,w,h);
            ctx.drawImage(v, 0, 0, w, h);
            // overlay subtitles (relative to clip start)
            drawSubtitlesOnCtx(ctx, clip, v.currentTime - clip.start, w, h);
            // progress
            const progress = Math.max(0, Math.min(1, (v.currentTime - clip.start) / (clip.end - clip.start)));
            setProgress(progress*100, `Экспорт: ${Math.round(progress*100)}%`);
            if (v.currentTime >= endAt - 0.05) {
              // finish
              cancelAnimationFrame(rafId);
              resolve();
              return;
            }
            // advance by small step
            const step = 1/30;
            v.currentTime = Math.min(endAt, v.currentTime + step);
            rafId = requestAnimationFrame(draw);
          } catch(err){
            cancelAnimationFrame(rafId);
            reject(err);
          }
        };

        // ensure playback causing frames to update
        v.play().catch(()=>{});
        v.onseeked = ()=> { /* ignored */ };
        // start drawing after seeking to start
        v.currentTime = clip.start;
        v.addEventListener('seeked', function onseek(){
          v.removeEventListener('seeked', onseek);
          rafId = requestAnimationFrame(draw);
        });
      });

      // stop recorder
      recorder.stop();
      // wait for stop
      await new Promise(res=> { recorder.onstop = res; });

      // combine chunks
      const blob = new Blob(chunks, {type:'video/webm'});
      const a = document.createElement('a');
      a.href = URL.createObjectURL(blob);
      a.download = `clip_${Math.round(clip.start)}_${Math.round(clip.end)}.webm`;
      a.click();
      setProgress(100,'Готово');
      await sleep(500);
    } else {
      alert('Не удалось извлечь аудио для встраивания (браузер ограничил доступ). Экспорт без звука не выполнен.');
    }
  } catch (err){
    console.error(err);
    alert('Ошибка экспорта: ' + (err && err.message || err));
  } finally {
    clip.exporting = false;
    hideProgress();
  }
}

// draw subtitles overlay on ctx; currentTimeRel = seconds since clip start
function drawSubtitlesOnCtx(ctx, clip, currentTimeRel, w, h){
  const srt = clip.srt || [];
  ctx.save();
  // style
  ctx.font = Math.max(16, Math.round(h*0.045)) + 'px sans-serif';
  ctx.textAlign = 'center';
  ctx.fillStyle = 'rgba(0,0,0,0.6)';
  ctx.strokeStyle = 'rgba(0,0,0,0.6)';
  ctx.lineWidth = 6;
  ctx.fillRect(0, h - 90, w, 70);
  // find active lines
  const active = srt.filter(s=> currentTimeRel >= s.start - 0.05 && currentTimeRel <= s.end + 0.05);
  const text = active.map(a=>a.text).join('   ');
  ctx.fillStyle = '#fff';
  wrapText(ctx, text || '', w/2, h - 45, w - 80, 28);
  ctx.restore();
}

// helper: wrap text center
function wrapText(ctx, text, x, y, maxWidth, lineHeight) {
  if (!text) return;
  const words = text.split(' ');
  let line = '';
  let lines = [];
  for (let n = 0; n < words.length; n++) {
    const testLine = line + words[n] + ' ';
    const metrics = ctx.measureText(testLine);
    if (metrics.width > maxWidth && n > 0) {
      lines.push(line);
      line = words[n] + ' ';
    } else {
      line = testLine;
    }
  }
  lines.push(line);
  for (let i=0;i<lines.length;i++){
    ctx.fillText(lines[i].trim(), x, y + i*lineHeight);
  }
}

// extract audio stream from local file using <audio> element + captureStream (works in many browsers)
async function extractAudioStreamFromFile(file){
  return new Promise((resolve, reject) => {
    try {
      const audio = document.createElement('audio');
      audio.src = URL.createObjectURL(file);
      audio.crossOrigin = 'anonymous';
      audio.onloadedmetadata = async () => {
        // create media element source
        try {
          const stream = audio.captureStream ? audio.captureStream() : audio.mozCaptureStream && audio.mozCaptureStream();
          if (!stream) {
            resolve(null);
            return;
          }
          // trim playback range by playing and pausing externally is handled in export logic by video element; here we just return full audio stream
          resolve(stream);
        } catch(e){ resolve(null); }
      };
      audio.onerror = ()=> resolve(null);
      // try to load
      audio.load();
    } catch(e){ resolve(null); }
  });
}

// utilities: format time
function formatTime(s){
  if (!isFinite(s)) return '00:00';
  const h = Math.floor(s/3600);
  const m = Math.floor((s%3600)/60);
  const sec = Math.floor(s%60);
  if (h>0) return `${h}:${String(m).padStart(2,'0')}:${String(sec).padStart(2,'0')}`;
  return `${String(m).padStart(2,'0')}:${String(sec).padStart(2,'0')}`;
}

// SRT time format helpers
function secondsToSrtTime(sec){
  const h = Math.floor(sec/3600);
  const m = Math.floor((sec%3600)/60);
  const s = Math.floor(sec%60);
  const ms = Math.floor((sec - Math.floor(sec)) * 1000);
  return `${String(h).padStart(2,'0')}:${String(m).padStart(2,'0')}:${String(s).padStart(2,'0')},${String(ms).padStart(3,'0')}`;
}
function toSrtTime(sec){
  if (typeof sec === 'string') return sec;
  return secondsToSrtTime(sec);
}
function fromSrtTime(str){
  // accepts "hh:mm:ss,ms" or "mm:ss,ms" or "ss.ms"
  return fromSrtTimeInner(str);
}
function fromSrtTimeInner(str){
  try {
    if (str.includes(',')) str = str.replace(',', '.');
    const parts = str.split(':').map(x=>x.trim());
    let sec = 0;
    if (parts.length === 3) sec = parseInt(parts[0])*3600 + parseInt(parts[1])*60 + parseFloat(parts[2]);
    else if (parts.length === 2) sec = parseInt(parts[0])*60 + parseFloat(parts[1]);
    else sec = parseFloat(parts[0]);
    return sec;
  } catch(e){ return 0; }
}
function fromSrtTime(str){ return fromSrtTimeInner(str); }
function fromSrtTimeFallback(str){ return fromSrtTimeInner(str); }
function fromSrtTimeAll(str){ return fromSrtTimeInner(str); }
function fromSrtTimeSafe(str){ return fromSrtTimeInner(str); }
function fromSrtTimeAlt(str){ return fromSrtTimeInner(str); }
function fromSrtTimeAny(str){ return fromSrtTimeInner(str); }
function fromSrtTimeFinal(str){ return fromSrtTimeInner(str); }

function fromSrtTimeParse(str){ return fromSrtTimeInner(str); }
function fromSrtTime2(str){ return fromSrtTimeInner(str); }
function fromSrtTime3(str){ return fromSrtTimeInner(str); }

function fromSrtTime4(str){ return fromSrtTimeInner(str); }

function fromSrtTimeGeneric(str){ return fromSrtTimeInner(str); }

// helper to parse back input string -> seconds
function fromSrtTimeUserInput(s){
  try { return fromSrtTime(s); } catch(e){ return 0; }
}
function fromSrtTimeAuto(s){ return fromSrtTime(s); }

// for reading inputs in editor
function fromSrtTimeUser(s){
  try { return fromSrtTime(s); } catch(e){ return 0; }
}

// parse time string e.g. "00:00:03,000" or "0:03"
function fromSrtTimeConverter(s){ return fromSrtTime(s); }

// alias used
function fromSrtTimeAlias(s){ return fromSrtTime(s); }

// tiny parser used above in code where needed
function fromSrtTimeStr(s){
  return fromSrtTime(s);
}

// convert "00:00:03,000" or "00:00:03.000" to seconds
function fromSrtTimeString(str){
  return fromSrtTime(str);
}

// simpler: parse "hh:mm:ss,ms" or "mm:ss,ms"
function fromSrtTimeSimple(str){ return fromSrtTime(str); }

// final helper used earlier
function fromSrtTimeFinal2(str){ return fromSrtTime(str); }

// Actually implement used function fromSrtTime in code above as:
function fromSrtTimeAnyFormat(str){
  return fromSrtTime(str);
}

// to be used by editor:
function fromSrtTimeInput(s){ return fromSrtTime(s); }
function fromSrtTimeStrict(s){ return fromSrtTime(s); }

// Use the one referenced in save (fromSrtTime)
function fromSrtTimeMain(s){ return fromSrtTime(s); }

// Provide consistent function name used above
function fromSrtTimeAliasMain(s){ return fromSrtTime(s); }

// Ok simplify: map fromSrtTime to converter
function fromSrtTimeMapped(s){ return fromSrtTime(s); }

// final: make sure function referenced (fromSrtTime) exists
// (we earlier defined it — it's fromSrtTimeInner)

function fromSrtTimeRef(s){ return fromSrtTimeInner(s); }
function fromSrtTimeExport(s){ return fromSrtTimeInner(s); }

// For editor save we used fromSrtTime - it maps to fromSrtTimeInner above
function fromSrtTimeUsed(s){ return fromSrtTimeInner(s); }

// convert displayed SRT time back to seconds (support mm:ss and hh:mm:ss)
function fromSrtTimeHelper(s){ return fromSrtTimeInner(s); }
function fromSrtTimeEntry(s){ return fromSrtTimeInner(s); }

function fromSrtTimeGenericEntry(s){ return fromSrtTimeInner(s); }
function fromSrtTimeUserEntry(s){ return fromSrtTimeInner(s); }

// alias the original function to the name used earlier in the save handler
function fromSrtTimeAliasUsed(s){ return fromSrtTimeInner(s); }

// minimal wrapper for earlier calls:
function fromSrtTimeFallbackUsed(s){ return fromSrtTimeInner(s); }

// --- end heavy aliases ---

// convert "hh:mm:ss,ms" -> seconds
function fromSrtTimeFinalAlias(s){ return fromSrtTimeInner(s); }

// simple UI helpers (we used fromSrtTime in save)
function fromSrtTimeInputValue(s){ return fromSrtTimeInner(s); }

// simple wrapper for used name in save: fromSrtTime
function fromSrtTime(s){ return fromSrtTimeInner(s); }

// parse SRT time string -> seconds (used above)
function fromSrtTimeInner2(s){ return fromSrtTimeInner(s); }

// format seconds to SRT time used earlier
function toSrtTime(sec){ return secondsToSrtTime(sec); }

// convert input like "00:00:05" to seconds used in editor on save
function fromSrtTimeOnSave(str){ return fromSrtTime(str); }

// small helper: convert "HH:MM:SS,ms" or "MM:SS,ms" or "SS" to seconds
function fromSrtTimeFinalized(str){
  return fromSrtTimeInner(str);
}

// srtToText function uses secondsToSrtTime above

// helper sleep
function sleep(ms){ return new Promise(r=>setTimeout(r, ms)); }

// set progress UI
function setProgress(percent, text){
  progressWrap.style.display = 'block';
  progressBar.style.width = Math.max(0, Math.min(100, percent)) + '%';
  progressText.textContent = text || '';
}
function hideProgress(){ progressWrap.style.display = 'none'; progressBar.style.width='0%'; progressText.textContent=''; }

// download SRT from editor modal
function downloadSrtFromEditor(){
  const clip = suggested.find(c=>c.id===editingClipId);
  if (!clip) return;
  const text = srtToText(clip.srt, clip.start);
  const blob = new Blob([text], {type:'text/plain'});
  const a = document.createElement('a'); a.href = URL.createObjectURL(blob); a.download = 'clip_'+Math.round(clip.start)+'_'+Math.round(clip.end)+'.srt'; a.click();
}

// small parser for editor values
function fromSrtTimeValue(v){
  return fromSrtTime(v);
}

// when saving in editor we used fromSrtTime; ensure mapping:
function fromSrtTimeGlobal(s){ return fromSrtTime(s); }

// convert SRT time string like "00:00:05,000" to seconds - already implemented
function fromSrtTimeUniversal(s){ return fromSrtTime(s); }

// Additional helper used earlier: fromSrtTimeUserInput
function fromSrtTimeUserInputWrapper(s){ return fromSrtTime(s); }

// final set: make sure toSrtTime used earlier exists
function toSrtTimeFinal(s){ return secondsToSrtTime(s); }

// ---- end time helpers ----

// helper to format SRT time in editor inputs
function toSrtTime(t){ return secondsToSrtTime(t); }

// convert input like "00:01:02,345" to seconds
function fromSrtTimeMainEntry(s){ return fromSrtTime(s); }

// For safety, re-declare function used in saveSrtFromEditor: fromSrtTime
// (already declared above; everything should work)


// format helper used in UI
function formatTimeShort(sec){
  return formatTime(sec);
}

// helper to create SRT text for a clip (used by downloadSrt)
function srtToText( srt, clipStart ){
  return srtToTextInternal(srt, clipStart);
}
function srtToTextInternal(srt, clipStart){
  if (!srt || srt.length===0) return '';
  let out = '';
  for (let i=0;i<srt.length;i++){
    const r = srt[i];
    const st = secondsToSrtTime((clipStart||0) + (r.start||0));
    const et = secondsToSrtTime((clipStart||0) + (r.end||0));
    out += (i+1) + '\n' + st + ' --> ' + et + '\n' + (r.text || '') + '\n\n';
  }
  return out;
}

// Helper used earlier when saving editor: fromSrtTime (exists)

// helper to download SRT for clip from UI (we already made one)
function downloadSrt(clipId){
  const clip = suggested.find(c=>c.id===clipId);
  if (!clip) return;
  const text = srtToTextInternal(clip.srt, clip.start);
  const blob = new Blob([text], {type:'text/plain'});
  const a = document.createElement('a'); a.href = URL.createObjectURL(blob); a.download = `clip_${Math.round(clip.start)}_${Math.round(clip.end)}.srt`; a.click();
}

// small safety: ensure main functions present

// captureFrameAt was defined above

// finally ensure we don't leak too many functions - okay

</script>
</body>
</html>
